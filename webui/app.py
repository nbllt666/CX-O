#!/usr/bin/env python3
"""
Gradio WebUIåº”ç”¨ï¼ˆå¸¦åç«¯æ§åˆ¶ï¼‰

åŠŸèƒ½ï¼š
- èŠå¤©é¡µé¢
- è®¾ç½®é¡µé¢ï¼ˆåç«¯å¯åŠ¨/åœæ­¢ï¼‰
- è®°å¿†ç®¡ç†é¡µé¢
- å¼¹å¹•ç›‘æ§é¡µé¢
"""

import gradio as gr
from gradio import themes
import json
import logging
from pathlib import Path

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class GradioApp:
    """Gradio WebUIåº”ç”¨"""
    
    def __init__(self, config: dict, backend_port: int = 8000):
        """
        åˆå§‹åŒ–WebUIåº”ç”¨
        
        Args:
            config: å…¨å±€é…ç½®
            backend_port: åç«¯æœåŠ¡ç«¯å£
        """
        self.config = config
        self.backend_port = backend_port
        self._backend_status = gr.State(value={"is_running": False})
        
        # åˆ›å»ºBlocks
        with gr.Blocks(
            title="ğŸŒ… æ™¨æ›¦Origins Agent",
            theme=themes.Soft()
        ) as self.app:
            self._build_ui()
    
    def _build_ui(self):
        """æ„å»ºUI"""
        # æ ‡é¢˜
        gr.Markdown("# ğŸŒ… æ™¨æ›¦Origins Agent")
        gr.Markdown("äººæ ¼åŒ–AIåŠ©æ‰‹ | é•¿æœŸè®°å¿† | å¤šæ¨¡æ€äº¤äº’ | å¼¹å¹•äº’åŠ¨")
        
        # çŠ¶æ€æ˜¾ç¤º
        status_display = gr.Markdown("âŒ åç«¯æœåŠ¡æœªå¯åŠ¨")
        
        # åç«¯æ§åˆ¶
        with gr.Row():
            start_backend_btn = gr.Button("ğŸš€ å¯åŠ¨åç«¯", variant="primary", scale=2)
            stop_backend_btn = gr.Button("â¹ï¸ åœæ­¢åç«¯", variant="stop", scale=2)
            refresh_status_btn = gr.Button("ğŸ”„ åˆ·æ–°çŠ¶æ€", scale=1)
        
        # é€‰é¡¹å¡
        with gr.Tabs():
            self._build_chat_tab()
            self._build_settings_tab()
            self._build_memory_tab()
            self._build_danmaku_tab()
        
        # åç«¯æ§åˆ¶äº‹ä»¶
        def start_backend(port):
            from main import BackendManager
            backend_port = 8000  # åç«¯å›ºå®šä½¿ç”¨8000ç«¯å£
            BackendManager.start_backend(backend_port)
            import time
            time.sleep(1)
            status = BackendManager.get_status()
            return f"âœ… åç«¯æœåŠ¡è¿è¡Œä¸­ (API: 8000)" if status["is_running"] else "âŒ åç«¯æœåŠ¡å¯åŠ¨å¤±è´¥"
        
        def stop_backend():
            from main import BackendManager
            BackendManager.stop_backend()
            return "âŒ åç«¯æœåŠ¡å·²åœæ­¢"
        
        def refresh_status():
            from main import BackendManager
            status = BackendManager.get_status()
            return f"âœ… åç«¯æœåŠ¡è¿è¡Œä¸­" if status["is_running"] else "âŒ åç«¯æœåŠ¡æœªå¯åŠ¨"
        
        start_backend_btn.click(start_backend, None, status_display)
        stop_backend_btn.click(stop_backend, None, status_display)
        refresh_status_btn.click(refresh_status, None, status_display)
    
    # ========== èŠå¤©é¡µé¢ ==========
    
    def _build_chat_tab(self):
        with gr.TabItem("ğŸ’¬ èŠå¤©"):
            with gr.Column(scale=1):
                # èŠå¤©å†å²
                chatbot = gr.Chatbot(
                    elem_id="chatbot",
                    type="messages",
                    avatar_images=("ğŸ¤–", "ğŸ‘¤")
                )
                
                # è¾“å…¥åŒºåŸŸ
                with gr.Row():
                    with gr.Column(scale=4):
                        text_input = gr.Textbox(
                            placeholder="è¾“å…¥æ¶ˆæ¯...ï¼ˆæ”¯æŒå¤šè¡Œè¾“å…¥ï¼‰",
                            lines=3,
                            elem_id="text_input",
                            show_label=False
                        )
                    
                    with gr.Column(scale=1):
                        audio_input = gr.Audio(
                            sources=["microphone"],
                            type="filepath",
                            label="ğŸ¤ è¯­éŸ³"
                        )
                
                # æŒ‰é’®
                with gr.Row():
                    submit_btn = gr.Button("å‘é€", variant="primary", scale=2)
                    clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯", variant="stop", scale=1)
                
                # éŸ³é¢‘è¾“å‡º
                audio_output = gr.Audio(
                    elem_id="audio_output",
                    label="ğŸ”Š è¯­éŸ³è¾“å‡º",
                    autoplay=True
                )
                
                # å¿«æ·æŒ‡ä»¤
                with gr.Accordion("ğŸ“ å¿«æ·æŒ‡ä»¤", open=False):
                    quick_prompts = [
                        "ä»Šå¤©æœ‰ä»€ä¹ˆæ–°é—»ï¼Ÿ",
                        "è®²ä¸ªç¬‘è¯",
                        "å¸®æˆ‘è®°ä½...",
                        "æœç´¢ç›¸å…³è®°å¿†"
                    ]
                    gr.Examples(
                        examples=quick_prompts,
                        inputs=text_input,
                        label="ç‚¹å‡»ä½¿ç”¨"
                    )
    
    # ========== è®¾ç½®é¡µé¢ ==========
    
    def _build_settings_tab(self):
        with gr.TabItem("âš™ï¸ è®¾ç½®"):
            with gr.Column():
                gr.Markdown("## ç³»ç»Ÿé…ç½®")
                
                # ä¸»æ¨¡å‹é€‰æ‹©
                with gr.Group():
                    gr.Markdown("### ğŸ¤– ä¸»æ¨¡å‹ï¼ˆè´Ÿè´£å¯¹è¯ï¼‰")
                    
                    llm_provider = gr.Dropdown(
                        ["vllm", "ollama"],
                        value=self.config.get('system', {}).get('llm_provider', 'vllm'),
                        label="é€‰æ‹©LLMæä¾›å•†",
                        info="vllmé€‚åˆæœ¬åœ°é«˜æ€§èƒ½æ¨ç†ï¼Œollamaé€‚åˆè½»é‡éƒ¨ç½²"
                    )
                    
                    # vLLMé…ç½®ï¼ˆé»˜è®¤æ˜¾ç¤ºï¼‰
                    with gr.Column(visible=True) as vllm_config:
                        vllm_host = gr.Textbox(
                            value=self.config.get('system', {}).get('vllm', {}).get('host', 'localhost'),
                            label="vLLM Host"
                        )
                        vllm_port = gr.Number(
                            value=self.config.get('system', {}).get('vllm', {}).get('port', 8000),
                            label="vLLM Port"
                        )
                        vllm_model = gr.Textbox(
                            value=self.config.get('system', {}).get('vllm', {}).get('model', 'Qwen2.5-7B-Instruct'),
                            label="æ¨¡å‹åç§°"
                        )
                    
                    # Ollamaé…ç½®ï¼ˆé»˜è®¤éšè—ï¼‰
                    with gr.Column(visible=False) as ollama_config:
                        ollama_host = gr.Textbox(
                            value=self.config.get('system', {}).get('ollama', {}).get('host', 'http://localhost:11434'),
                            label="Ollama Host"
                        )
                        ollama_model = gr.Textbox(
                            value=self.config.get('system', {}).get('ollama', {}).get('model', 'llama3.2'),
                            label="æ¨¡å‹åç§°"
                        )
                    
                    # åˆ‡æ¢æ˜¾ç¤º/éšè—
                    def toggle_provider(provider):
                        return {
                            vllm_config: gr.update(visible=provider == "vllm"),
                            ollama_config: gr.update(visible=provider == "ollama")
                        }
                    
                    llm_provider.change(toggle_provider, llm_provider, [vllm_config, ollama_config])
                
                # å‰¯æ¨¡å‹é€‰æ‹©
                with gr.Group():
                    gr.Markdown("### ğŸ”§ å‰¯æ¨¡å‹ï¼ˆè´Ÿè´£è®°å¿†ç®¡ç†/å¼¹å¹•å®¡æ ¸ï¼‰")
                    
                    assistant_provider = gr.Dropdown(
                        ["vllm", "ollama"],
                        value=self.config.get('system', {}).get('assistant_provider', 'vllm'),
                        label="é€‰æ‹©LLMæä¾›å•†"
                    )
                    
                    with gr.Column() as assistant_vllm_config:
                        assistant_vllm_host = gr.Textbox(
                            value=self.config.get('system', {}).get('assistant_vllm', {}).get('host', 'localhost'),
                            label="vLLM Host"
                        )
                        assistant_vllm_model = gr.Textbox(
                            value=self.config.get('system', {}).get('assistant_vllm', {}).get('model', 'Qwen2.5-1.5B-Instruct'),
                            label="æ¨¡å‹åç§°"
                        )
                    
                    with gr.Column(visible=False) as assistant_ollama_config:
                        assistant_ollama_host = gr.Textbox(
                            value=self.config.get('system', {}).get('assistant_ollama', {}).get('host', 'http://localhost:11434'),
                            label="Ollama Host"
                        )
                        assistant_ollama_model = gr.Textbox(
                            value=self.config.get('system', {}).get('assistant_ollama', {}).get('model', 'llama3.2'),
                            label="æ¨¡å‹åç§°"
                        )
                    
                    def toggle_assistant_provider(provider):
                        return {
                            assistant_vllm_config: gr.update(visible=provider == "vllm"),
                            assistant_ollama_config: gr.update(visible=provider == "ollama")
                        }
                    
                    assistant_provider.change(toggle_assistant_provider, assistant_provider, [assistant_vllm_config, assistant_ollama_config])
                
                # è®°å¿†é…ç½®
                with gr.Group():
                    gr.Markdown("### è®°å¿†é…ç½®")
                    
                    archive_interval = gr.Number(
                        value=self.config.get('memory', {}).get('archive_interval', 3600),
                        label="å½’æ¡£é—´éš”ï¼ˆç§’ï¼‰"
                    )
                    retrieval_limit = gr.Slider(
                        minimum=1,
                        maximum=20,
                        value=self.config.get('memory', {}).get('retrieval_limit', 10),
                        label="æ£€ç´¢æ•°é‡"
                    )
                    max_history_rounds = gr.Slider(
                        minimum=5,
                        maximum=50,
                        value=self.config.get('memory', {}).get('max_history_rounds', 20),
                        label="ä¿ç•™å†å²è½®æ•°"
                    )
                
                # å¼¹å¹•é…ç½®
                with gr.Group():
                    gr.Markdown("### å¼¹å¹•é…ç½®")
                    
                    danmaku_enable = gr.Checkbox(
                        value=self.config.get('danmaku', {}).get('enabled', True),
                        label="å¯ç”¨å¼¹å¹•ç›‘å¬"
                    )
                    danmaku_uri = gr.Textbox(
                        value=self.config.get('danmaku', {}).get('websocket_uri', 'ws://localhost:9898'),
                        label="å¼¹å¹•æœåŠ¡å™¨URI"
                    )
                    danmaku_room_id = gr.Textbox(
                        value=",".join(self.config.get('danmaku', {}).get('task_ids', [])),
                        label="æˆ¿é—´å·ï¼ˆé€—å·åˆ†éš”ï¼‰"
                    )
                    audit_enabled = gr.Checkbox(
                        value=self.config.get('danmaku', {}).get('audit_enabled', True),
                        label="å¯ç”¨å¼¹å¹•å®¡æ ¸"
                    )
                
                # è¯­éŸ³é…ç½®
                with gr.Group():
                    gr.Markdown("### ğŸ¤ è¯­éŸ³é…ç½®")
                    
                    # TTSé…ç½®
                    gr.Markdown("#### TTSï¼ˆè¯­éŸ³åˆæˆï¼‰")
                    tts_provider = gr.Dropdown(
                        ["edge", "f5-tts"],
                        value=self.config.get('tts', {}).get('provider', 'edge'),
                        label="TTSæä¾›å•†",
                        info="edge=å¾®è½¯è¯­éŸ³ï¼Œf5-tts=å¼€æºå…‹éš†"
                    )
                    
                    with gr.Column(visible=True) as edge_tts_config:
                        tts_voice = gr.Dropdown(
                            ["zh-CN-XiaoxiaoNeural", "zh-CN-YunxiNeural", "zh-CN-XiaoyouNeural"],
                            value=self.config.get('tts', {}).get('voice', 'zh-CN-XiaoxiaoNeural'),
                            label="è¯­éŸ³è§’è‰²"
                        )
                    
                    with gr.Column(visible=False) as f5_tts_config:
                        tts_voice_ref = gr.Textbox(
                            value=self.config.get('tts', {}).get('voice_ref', ''),
                            label="å‚è€ƒéŸ³é¢‘è·¯å¾„",
                            info="F5-TTSéœ€è¦æä¾›å‚è€ƒéŸ³é¢‘"
                        )
                    
                    def toggle_tts_provider(provider):
                        return {
                            edge_tts_config: gr.update(visible=provider == "edge"),
                            f5_tts_config: gr.update(visible=provider == "f5-tts")
                        }
                    
                    tts_provider.change(toggle_tts_provider, tts_provider, [edge_tts_config, f5_tts_config])
                    
                    # ASRé…ç½®
                    gr.Markdown("#### ASRï¼ˆè¯­éŸ³è¯†åˆ«ï¼‰")
                    asr_provider = gr.Dropdown(
                        ["sensevoice", "whisper"],
                        value=self.config.get('asr', {}).get('provider', 'sensevoice'),
                        label="ASRæä¾›å•†",
                        info="sensevoice=å¼€æºå®æ—¶è¯†åˆ«ï¼Œwhisper=OpenAI"
                    )
                    asr_use_gpu = gr.Checkbox(
                        value=self.config.get('asr', {}).get('use_gpu', True),
                        label="ä½¿ç”¨GPUåŠ é€Ÿ"
                    )
                
                # ä¿å­˜æŒ‰é’®
                save_btn = gr.Button("ä¿å­˜é…ç½®", variant="primary")
                
                # ä¿å­˜çŠ¶æ€
                save_status = gr.Markdown()
                
                # ä¿å­˜é…ç½®å‡½æ•°
                def save_config(
                    provider, vllm_host, vllm_port, vllm_model,
                    ollama_host, ollama_model,
                    assistant_provider, assistant_vllm_host, assistant_vllm_model,
                    assistant_ollama_host, assistant_ollama_model,
                    archive_interval, retrieval_limit, max_history_rounds,
                    danmaku_enable, danmaku_uri, danmaku_room_id, audit_enabled,
                    tts_provider, tts_voice, tts_voice_ref,
                    asr_provider, asr_use_gpu
                ):
                    config = {
                        "system": {
                            "llm_provider": provider,
                            "vllm": {
                                "host": vllm_host,
                                "port": vllm_port,
                                "model": vllm_model
                            },
                            "ollama": {
                                "host": ollama_host,
                                "model": ollama_model
                            },
                            "assistant_provider": assistant_provider,
                            "assistant_vllm": {
                                "host": assistant_vllm_host,
                                "model": assistant_vllm_model
                            },
                            "assistant_ollama": {
                                "host": assistant_ollama_host,
                                "model": assistant_ollama_model
                            }
                        },
                        "memory": {
                            "archive_interval": archive_interval,
                            "retrieval_limit": retrieval_limit,
                            "max_history_rounds": max_history_rounds
                        },
                        "danmaku": {
                            "enabled": danmaku_enable,
                            "websocket_uri": danmaku_uri,
                            "task_ids": [x.strip() for x in danmaku_room_id.split(",") if x.strip()],
                            "audit_enabled": audit_enabled
                        },
                        "tts": {
                            "provider": tts_provider,
                            "voice": tts_voice,
                            "voice_ref": tts_voice_ref
                        },
                        "asr": {
                            "provider": asr_provider,
                            "use_gpu": asr_use_gpu
                        }
                    }
                    
                    config_path = Path(__file__).parent / "config.json"
                    with open(config_path, "w", encoding="utf-8") as f:
                        import json
                        json.dump(config, f, ensure_ascii=False, indent=2)
                    
                    return "âœ… é…ç½®å·²ä¿å­˜åˆ° config.json"
                
                save_btn.click(
                    save_config,
                    inputs=[
                        llm_provider, vllm_host, vllm_port, vllm_model,
                        ollama_host, ollama_model,
                        assistant_provider, assistant_vllm_host, assistant_vllm_model,
                        assistant_ollama_host, assistant_ollama_model,
                        archive_interval, retrieval_limit, max_history_rounds,
                        danmaku_enable, danmaku_uri, danmaku_room_id, audit_enabled,
                        tts_provider, tts_voice, tts_voice_ref,
                        asr_provider, asr_use_gpu
                    ],
                    outputs=save_status
                )
    
    # ========== è®°å¿†ç®¡ç†é¡µé¢ ==========
    
    def _build_memory_tab(self):
        with gr.TabItem("ğŸ§  è®°å¿†ç®¡ç†"):
            with gr.Column():
                gr.Markdown("## è®°å¿†ç®¡ç†")
                
                # æœç´¢
                with gr.Row():
                    search_input = gr.Textbox(
                        placeholder="æœç´¢è®°å¿†...",
                        label="æœç´¢",
                        scale=4
                    )
                    search_btn = gr.Button("æœç´¢", scale=1)
                
                # æ·»åŠ è®°å¿†
                with gr.Accordion("â• æ·»åŠ è®°å¿†", open=False):
                    new_content = gr.Textbox(
                        lines=3,
                        placeholder="è¾“å…¥è¦è®°å¿†çš„å†…å®¹...",
                        label="è®°å¿†å†…å®¹"
                    )
                    
                    with gr.Row():
                        memory_type = gr.Dropdown(
                            ["permanent", "long_term", "short_term"],
                            value="long_term",
                            label="è®°å¿†ç±»å‹",
                            scale=2
                        )
                        importance = gr.Slider(
                            minimum=1,
                            maximum=5,
                            value=3,
                            label="é‡è¦æ€§",
                            step=1,
                            scale=1
                        )
                    
                    tags = gr.Textbox(
                        placeholder="æ ‡ç­¾ï¼ˆé€—å·åˆ†éš”ï¼‰",
                        label="æ ‡ç­¾"
                    )
                    
                    add_btn = gr.Button("æ·»åŠ è®°å¿†", variant="primary")
                
                # è®°å¿†åˆ—è¡¨
                memory_list = gr.Dataframe(
                    headers=["ID", "ç±»å‹", "å†…å®¹", "é‡è¦æ€§", "æ ‡ç­¾", "åˆ›å»ºæ—¶é—´"],
                    interactive=True,
                    label="è®°å¿†åˆ—è¡¨"
                )
                
                # æ“ä½œæŒ‰é’®
                with gr.Row():
                    delete_btn = gr.Button("ğŸ—‘ï¸ åˆ é™¤é€‰ä¸­", variant="stop")
                    export_btn = gr.Button("ğŸ“¤ å¯¼å‡º")
                    import_btn = gr.Button("ğŸ“¥ å¯¼å…¥")
                
                # ç»Ÿè®¡ä¿¡æ¯
                with gr.Row():
                    total_memories = gr.Number(value=0, label="æ€»è®°å¿†æ•°")
                    permanent_count = gr.Number(value=0, label="æ°¸ä¹…è®°å¿†")
                    long_term_count = gr.Number(value=0, label="é•¿æœŸè®°å¿†")
    
    # ========== å¼¹å¹•ç›‘æ§é¡µé¢ ==========
    
    danmaku_status = gr.State(value={"connected": False, "plugin": None})
    
    def _build_danmaku_tab(self):
        with gr.TabItem("ğŸ“Š å¼¹å¹•ç›‘æ§"):
            with gr.Column():
                gr.Markdown("## å¼¹å¹•ç›‘æ§")
                
                # çŠ¶æ€æ˜¾ç¤º
                danmaku_status_display = gr.Markdown("âŒ æœªè¿æ¥")
                
                # è¿æ¥æ§åˆ¶
                with gr.Row():
                    danmaku_uri = gr.Textbox(
                        value=self.config.get('danmaku', {}).get('websocket_uri', 'ws://localhost:9898'),
                        label="å¼¹å¹•æœåŠ¡å™¨URI",
                        scale=3
                    )
                    connect_btn = gr.Button("ğŸ”— è¿æ¥", variant="primary", scale=1)
                    disconnect_btn = gr.Button("âŒ æ–­å¼€", variant="stop", scale=1)
                
                # å®æ—¶å¼¹å¹•æµ
                gr.Markdown("### å®æ—¶å¼¹å¹•")
                danmaku_feed = gr.Dataframe(
                    headers=["æ—¶é—´", "ç”¨æˆ·", "å†…å®¹", "å®¡æ ¸çŠ¶æ€"],
                    label="å¼¹å¹•æµ"
                )
                
                # ç»Ÿè®¡ä¿¡æ¯
                with gr.Row():
                    total_count = gr.Number(value=0, label="æ€»å¼¹å¹•æ•°")
                    approved_count = gr.Number(value=0, label="å·²é€šè¿‡")
                    rejected_count = gr.Number(value=0, label="å·²æ‹’ç»")
                    pending_count = gr.Number(value=0, label="å¾…å®¡æ ¸")
                
                # å®¡æ ¸æ—¥å¿—
                with gr.Accordion("ğŸ“‹ å®¡æ ¸æ—¥å¿—", open=False):
                    audit_log = gr.Dataframe(
                        headers=["æ—¶é—´", "ç”¨æˆ·", "å†…å®¹", "å®¡æ ¸ç»“æœ", "åŸå› "]
                    )
                
                # è¿æ¥/æ–­å¼€äº‹ä»¶
                def connect_danmaku(uri):
                    from plugins.danmaku import DanmakuPlugin
                    from core.danmaku_cache import DanmakuCacheManager
                    
                    cache = DanmakuCacheManager()
                    plugin = DanmakuPlugin(cache)
                    
                    try:
                        # åœ¨åå°ä»»åŠ¡ä¸­è¿æ¥
                        import asyncio
                        loop = asyncio.new_event_loop()
                        asyncio.set_loop(loop)
                        loop.run_until_complete(plugin.connect(uri, []))
                        
                        self.danmaku_status = {"connected": True, "plugin": plugin}
                        return "âœ… å·²è¿æ¥åˆ°å¼¹å¹•æœåŠ¡å™¨"
                    except Exception as e:
                        return f"âŒ è¿æ¥å¤±è´¥: {str(e)}"
                
                def disconnect_danmaku():
                    plugin = self.danmaku_status.get("value", {}).get("plugin")
                    if plugin:
                        import asyncio
                        loop = asyncio.new_event_loop()
                        asyncio.set_loop(loop)
                        loop.run_until_complete(plugin.disconnect())
                    
                    self.danmaku_status = {"connected": False, "plugin": None}
                    return "âŒ å·²æ–­å¼€è¿æ¥"
                
                connect_btn.click(connect_danmaku, danmaku_uri, danmaku_status_display)
                disconnect_btn.click(disconnect_danmaku, None, danmaku_status_display)
    
    def launch(self, host="0.0.0.0", port=7860, share=True):
        """
        å¯åŠ¨WebUI
        
        Args:
            host: ç›‘å¬åœ°å€ï¼ˆ0.0.0.0æ”¯æŒå¤–éƒ¨è®¿é—®ï¼‰
            port: ç«¯å£
            share: æ˜¯å¦åˆ›å»ºå…¬å…±é“¾æ¥ï¼ˆç”¨äºå¤–éƒ¨è®¿é—®ï¼‰
        """
        logger.info(f"å¯åŠ¨WebUI: http://{host}:{port}")
        
        self.app.launch(
            server_name=host,
            server_port=port,
            share=share,
            show_api=False
        )


def create_gradio_app_with_backend(config: dict, webui_port: int = 7860) -> GradioApp:
    """åˆ›å»ºå¸¦åç«¯æ§åˆ¶çš„Gradioåº”ç”¨"""
    return GradioApp(config, webui_port)


if __name__ == "__main__":
    # é»˜è®¤é…ç½®
    default_config = {
        "system": {
            "llm_provider": "vllm",
            "vllm": {
                "host": "localhost",
                "port": 8000,
                "model": "Qwen2.5-7B-Instruct"
            },
            "ollama": {
                "host": "http://localhost:11434",
                "model": "llama3.2"
            },
            "main_port": 8000,
            "webui_port": 7860,
            "log_level": "INFO"
        },
        "memory": {
            "context_dir": "data/contexts",
            "vector_dimension": 1024,
            "archive_interval": 3600,
            "retrieval_limit": 10,
            "max_history_rounds": 20
        },
        "danmaku": {
            "enabled": True,
            "websocket_uri": "ws://localhost:9898",
            "task_ids": [],
            "audit_enabled": True
        },
        "audio": {
            "effects_dir": "data/effects"
        }
    }
    
    app = create_gradio_app_with_backend(default_config)
    app.launch()
